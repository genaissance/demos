{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3d26db",
   "metadata": {},
   "source": [
    "## Step 2: Vectorize the input data - Azure version\n",
    "\n",
    "In this step, we will create a json file with mathematical vectors for all the text in the files we downloaded and cleaned in Step 1. This type of vectorization is powered by large language models and provides the basis for next-generation search capabilities. In this step, we will call the OpenAI Ada-002 model to provide the vectors, and the davinci model to assist with the indexing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45718f4-1188-4f7b-9893-80f2a062050c",
   "metadata": {},
   "source": [
    "- Execute the following cell to install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379978ab-0412-4bf8-b951-8e0a12b3d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "!pip install langchain\n",
    "!pip install llama_index\n",
    "message = \"The required packages have been installed\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a7c480-4abe-40b4-940f-69003e1805b4",
   "metadata": {},
   "source": [
    "- Execute the following cell to import required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05e71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from llama_index import LangchainEmbedding\n",
    "from llama_index import (\n",
    "    GPTSimpleVectorIndex,\n",
    "    SimpleDirectoryReader, \n",
    "    LLMPredictor,\n",
    "    PromptHelper,\n",
    "    ServiceContext\n",
    ")\n",
    "message = \"The dependencies have been imported\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a962f8",
   "metadata": {},
   "source": [
    "- Enter your API Key and Azure OpenAI Configuration Details Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0abf68-7a63-42db-a433-b2da261890ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# azure usage copied from examples: https://github.com/jerryjliu/llama_index/blob/main/examples/azure_demo/AzureOpenAI.ipynb\n",
    "# and https://github.com/hwchase17/langchain/issues/2377\n",
    "# and https://python.langchain.com/en/latest/modules/models/chat/integrations/azure_chat_openai.html\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://my_endpoint.openai.azure.com/\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-03-15-preview\" # enter your preferred API version if needed\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"REPLACE_WITH_YOUR_AZURE_OPENAI_KEY\" \n",
    "# Note the model deployment names are the names of your azure deployments, not the names of the models. The model_deployment_name values on the following 2 lines what I named my azure model deployments.\n",
    "os.environ[\"AZURE_QUERY_MODEL_DEPLOYMENT_NAME\"] = \"REPLACE_WITH_YOUR_AZURE_DEPLOYMENT_NAME_FOR_QUERY_MODEL\"\n",
    "os.environ[\"AZURE_EMBEDDINGS_MODEL_DEPLOYMENT_NAME\"] = \"REPLACE_WITH_YOUR_AZURE_DEPLOYMENT_NAME_FOR_EMBEDDINGS_MODEL\"\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.azure_query_deployment = os.getenv(\"AZURE_QUERY_MODEL_DEPLOYMENT_NAME\")\n",
    "openai.azure_embeddings_deployment = os.getenv(\"AZURE_EMBEDDINGS_MODEL_DEPLOYMENT_NAME\")\n",
    "message = \"The api settings have been loaded\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaaafdf",
   "metadata": {},
   "source": [
    "- The code block below defines the model parameters for: \n",
    "  - \"llm\" which is used for queries \n",
    "  - \"embedding_llm\" which is used for creating the vector db and indices\n",
    "- Execute the below code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2569cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    openai_api_base=openai.api_base,\n",
    "    openai_api_version=openai.api_version,\n",
    "    deployment_name=openai.azure_query_deployment,\n",
    "    openai_api_key=openai.api_key,\n",
    "    openai_api_type=openai.api_type,\n",
    ")\n",
    "\n",
    "# llm = AzureOpenAI(deployment_name=openai.azure_query_deployment, model_kwargs={\n",
    "#     \"api_key\": openai.api_key,\n",
    "#     \"api_base\": openai.api_base,\n",
    "#     \"api_type\": openai.api_type,\n",
    "#     \"api_version\": openai.api_version,\n",
    "# })\n",
    "llm_predictor = LLMPredictor(llm=llm)\n",
    "\n",
    "embedding_llm = LangchainEmbedding(OpenAIEmbeddings(\n",
    "    document_model_name=openai.azure_embeddings_deployment,\n",
    "    query_model_name=openai.azure_query_deployment\n",
    "))\n",
    "\n",
    "documents = SimpleDirectoryReader('html_downloads').load_data()\n",
    "message = \"The model settings have been defined, and the documents are loaded for indexing\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5cb4d5-0aaa-4a29-bf5b-e334b39bf25e",
   "metadata": {},
   "source": [
    "- This block is currently unused, but left here for reference. If you want to customize the prompt_helper, uncomment this section, and add the prompt_helper to the service_context in the next code block below\n",
    "- You can skip to the next block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d1c8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # max LLM token input size\n",
    "# max_input_size = 500\n",
    "# # set number of output tokens\n",
    "# num_output = 48\n",
    "# # set maximum chunk overlap\n",
    "# max_chunk_overlap = 20\n",
    "\n",
    "# prompt_helper = PromptHelper(max_input_size, num_output, max_chunk_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff24960-59fd-4bfd-9d76-a5161b4e0fa5",
   "metadata": {},
   "source": [
    "- The following code block sets calls openai ada-002 model to generate embeddings to populate the vector db, and creates the vector db and indices.\n",
    "- It may take several seconds before you see any return text\n",
    "- You may see errors indicating you have exceeded the Azure OpenAI rate limit. You can most likely ignore these errors as the rate limit is more than enough for most jobs, sometimes this code may try to send a little too fast, but it should retry until it completes successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aac5a6-495e-40d2-82d3-bda8688ae919",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(\n",
    "    llm_predictor=llm_predictor,\n",
    "    embed_model=embedding_llm\n",
    ")\n",
    "index = GPTSimpleVectorIndex.from_documents(documents, service_context=service_context)\n",
    "index.save_to_disk('testindex.azure.json')\n",
    "message = \"The index has been saved\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0276dee7-c5ea-4732-936f-e20532cb8ed4",
   "metadata": {},
   "source": [
    "### Now, query ChatGPT with context from your data source!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e33f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(\"how can I install tanzu application platform?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277fff78-4c3c-472e-ac91-df2054df9f45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
