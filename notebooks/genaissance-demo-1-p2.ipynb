{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a5fd303-fe9c-4a1c-b9f6-2a5028a3a01a",
   "metadata": {},
   "source": [
    "## Step 2: Vectorize the input data\n",
    "\n",
    "In this step, we will create a json file with mathematical vectors for all the text in the files we downloaded and cleaned in Step 1. This type of vectorization is powered by large language models and provides the basis for next-generation search capabilities. In this step, we will call the OpenAI Ada-002 model to provide the vectors, and the davinci model to assist with the indexing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf7ce3-ead0-4a03-8d97-c709d75c92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required Packages\n",
    "!pip install llama_index\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02e7f7e-df2e-4b61-8a64-a3da21cdf4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required dependencies\n",
    "from pathlib import Path\n",
    "from llama_index import LLMPredictor, GPTSimpleVectorIndex, PromptHelper, ServiceContext, SimpleDirectoryReader, download_loader\n",
    "from langchain import OpenAI\n",
    "from langchain.llms import OpenAIChat\n",
    "import json\n",
    "import os\n",
    "message = \"The dependencies have been imported\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adafa79-df27-4690-bd86-14ed7f25838c",
   "metadata": {},
   "source": [
    "__REQUIRED: Enter your OpenAI Api Key below by replacing the text REPLACE_WITH_OPENAI_API_KEY with your key:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e326b7-d80b-475c-a2bb-f9ee2069d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'REPLACE_WITH_OPENAI_API_KEY'\n",
    "message = \"The OPENAI_API_KEY Has been loaded\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d5253-f071-4432-a675-5bd23db23d09",
   "metadata": {},
   "source": [
    "_Execute the code block below to vectorize your data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc69c3c2-a840-49f1-b851-58a3c7dbbf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenAI.api_key = os.environ.get('OPENAI_API_KEY')\n",
    "SimpleDirectoryReader = download_loader(\"SimpleDirectoryReader\")\n",
    "\n",
    "# # set maximum input size\n",
    "# max_input_size = 4096\n",
    "# # set number of output tokens\n",
    "# num_outputs = 4096\n",
    "# # set maximum chunk overlap\n",
    "# max_chunk_overlap = 40\n",
    "# # set chunk size limit\n",
    "# chunk_size_limit = 600\n",
    "\n",
    "# define LLM\n",
    "llm_predictor = LLMPredictor(llm=OpenAIChat(\n",
    "    temperature=0, model_name=\"gpt-3.5-turbo\"))\n",
    "# prompt_helper = PromptHelper(max_input_size,\n",
    "#                              num_outputs,\n",
    "#                              max_chunk_overlap,\n",
    "#                              chunk_size_limit=chunk_size_limit)\n",
    "\n",
    "\n",
    "# loader = UnstructuredReader()\n",
    "# documents = loader.load_data(file=Path('/root/html/GUID-build-images-index.html'))\n",
    "\n",
    "loader = SimpleDirectoryReader('html_downloads').load_data()\n",
    "documents = loader\n",
    "\n",
    "# print(documents)\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor)\n",
    "\n",
    "index = GPTSimpleVectorIndex.from_documents(\n",
    "    documents, service_context=service_context\n",
    ")\n",
    "\n",
    "index.save_to_disk('testindex.json')\n",
    "message = \"The index has been saved\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34e3e8e-4979-4679-970c-bcc7d7221c7c",
   "metadata": {},
   "source": [
    "### Review Step2 Outputs\n",
    "\n",
    "Congratulations, you made it through step 2! Your data has now been vectorized!\n",
    "\n",
    "- In the left nav bar, you should see a file named \"testindex.json\". This file was created by the previous code block and contains the vectors for your dataset. Its typically a pretty large file and does not open easily in most readers, so its better not to open it and proceed to next step, where we will load the vectors into an in-memory database and finally query our data! \n",
    "\n",
    "## Now, query the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a316c3a-9dfb-44b9-b183-3d0127a6d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(\"Can you tell me whats new in Tanzu Application Platform 1.4\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb934bdd-c51a-4b5e-b271-a7d4c2f5f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(\"how can I install tanzu application platform?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39555611-2345-4a17-87d0-4a6fde4385b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(\"What is Namespace Provisioner and what problem does it solve?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538b0c7d-900b-42db-a181-0be88e74594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(\"What components make up the Namespace Provisioner package and how do they work together?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2704ef7f-2fde-4af7-beec-02cdda3bf326",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(\"what is tanzu application platform?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a8f27-161b-499a-a155-f257e635423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(\"What resources are contained in the default-resources secret and how are they templated?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f815ff0-2a2a-4a93-85ba-b986d7620e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
